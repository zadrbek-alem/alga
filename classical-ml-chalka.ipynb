{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T01:12:35.459030Z","iopub.execute_input":"2025-05-03T01:12:35.459330Z","iopub.status.idle":"2025-05-03T01:12:35.465445Z","shell.execute_reply.started":"2025-05-03T01:12:35.459306Z","shell.execute_reply":"2025-05-03T01:12:35.464646Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":172},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ngender_submission = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\n\ntrain = train.drop([\"Name\", \"PassengerId\", \"Ticket\", \"Cabin\"], axis=1)\ntest = test.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T01:12:36.254766Z","iopub.execute_input":"2025-05-03T01:12:36.255061Z","iopub.status.idle":"2025-05-03T01:12:36.271161Z","shell.execute_reply.started":"2025-05-03T01:12:36.255038Z","shell.execute_reply":"2025-05-03T01:12:36.270364Z"}},"outputs":[],"execution_count":173},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ntrain = train.drop(train[train[\"Embarked\"].isnull()].index, axis=0)\ntest = test.drop(test[test[\"Embarked\"].isnull()].index, axis=0)\ntest.loc[test[\"Fare\"].isnull(), \"Fare\"] = test[\"Fare\"].mean()\n\nctrain = train.copy()\nctest = test.copy()\n\nfor col in [\"Sex\", \"Embarked\"]:\n    ctrain[col] = ctrain[col].astype(str)\n    ctest[col] = ctest[col].astype(str)\n    le = LabelEncoder()\n    ctrain[col] = le.fit_transform(ctrain[col])\n    le = LabelEncoder()\n    ctest[col] = le.fit_transform(ctest[col])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T01:12:36.522323Z","iopub.execute_input":"2025-05-03T01:12:36.522638Z","iopub.status.idle":"2025-05-03T01:12:36.535597Z","shell.execute_reply.started":"2025-05-03T01:12:36.522617Z","shell.execute_reply":"2025-05-03T01:12:36.534744Z"}},"outputs":[],"execution_count":174},{"cell_type":"markdown","source":"### Fillining in nan for Age","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nimport random\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\", \"Fare\"]\n\nage_df = ctrain[ctrain[\"Age\"].notnull()]\nage_missing = ctrain[ctrain[\"Age\"].isnull()]\n\nlr = LinearRegression()\nlr.fit(age_df[features], age_df[\"Age\"])\npreds = lr.predict(age_missing[features])\npreds = np.maximum(preds, (preds * -1) + (preds / 2))\nctrain.loc[ctrain[\"Age\"].isnull(), \"Age\"] = preds\n\nage_df = ctest[ctest[\"Age\"].notnull()]\nage_missing = ctest[ctest[\"Age\"].isnull()]\n\nlr = LinearRegression()\nlr.fit(age_df[features], age_df[\"Age\"])\npreds = lr.predict(age_missing[features])\npreds = np.maximum(preds, (preds * -1) + (preds / 2))\nctest.loc[ctest[\"Age\"].isnull(), \"Age\"] = preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T01:12:36.952054Z","iopub.execute_input":"2025-05-03T01:12:36.952393Z","iopub.status.idle":"2025-05-03T01:12:36.975053Z","shell.execute_reply.started":"2025-05-03T01:12:36.952369Z","shell.execute_reply":"2025-05-03T01:12:36.973939Z"}},"outputs":[],"execution_count":175},{"cell_type":"markdown","source":"### Removing outliers in train","metadata":{}},{"cell_type":"code","source":"for col in [\"Age\"]:\n    Q1 = ctrain[col].quantile(0.25)\n    Q3 = ctrain[col].quantile(0.75)\n    IQR = Q3 - Q1\n    \n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    ctrain = ctrain[(ctrain[col] >= lower_bound) & (ctrain[col] <= upper_bound)]\n\nctrain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T01:12:38.482531Z","iopub.execute_input":"2025-05-03T01:12:38.482834Z","iopub.status.idle":"2025-05-03T01:12:38.499236Z","shell.execute_reply.started":"2025-05-03T01:12:38.482811Z","shell.execute_reply":"2025-05-03T01:12:38.498282Z"}},"outputs":[{"execution_count":176,"output_type":"execute_result","data":{"text/plain":"     Survived  Pclass  Sex        Age  SibSp  Parch     Fare  Embarked\n0           0       3    1  22.000000      1      0   7.2500         2\n1           1       1    0  38.000000      1      0  71.2833         0\n2           1       3    0  26.000000      0      0   7.9250         2\n3           1       1    0  35.000000      1      0  53.1000         2\n4           0       3    1  35.000000      0      0   8.0500         2\n..        ...     ...  ...        ...    ...    ...      ...       ...\n886         0       2    1  27.000000      0      0  13.0000         2\n887         1       1    0  19.000000      0      0  30.0000         2\n888         0       3    0  19.660027      1      2  23.4500         2\n889         1       1    1  26.000000      0      0  30.0000         0\n890         0       3    1  32.000000      0      0   7.7500         1\n\n[862 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>22.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>26.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>35.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>35.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>27.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>19.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>19.660027</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>26.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>32.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>862 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":176},{"cell_type":"markdown","source":"### Model training with default parameters","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\nmodel = xgb.XGBClassifier(\n    n_estimators=100,        # Number of boosting rounds\n    max_depth=4,             # Controls complexity (3–6 is common)\n    learning_rate=0.1,       # Lower learning rate, better generalization\n    subsample=0.8,           # Row subsampling (prevents overfitting)\n    colsample_bytree=0.8,    # Feature subsampling\n    objective='binary:logistic',\n    eval_metric='logloss',   # Metric to evaluate performance\n    use_label_encoder=False, # Suppress label encoder warning\n    random_state=42\n)\n\nfeatures = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Embarked\", \"Fare\"]\nX_train, X_test, y_train, y_test = train_test_split(ctrain[features], ctrain[\"Survived\"], random_state=42)\n\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_test, y_test)], \n    early_stopping_rounds=10,     \n    verbose=True\n)\n\npreds = model.predict(ctest[features])\nctest[\"Survived\"] = preds\n\nctest[[\"PassengerId\", \"Survived\"]].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T01:20:03.989883Z","iopub.execute_input":"2025-05-03T01:20:03.990245Z","iopub.status.idle":"2025-05-03T01:20:04.141377Z","shell.execute_reply.started":"2025-05-03T01:20:03.990220Z","shell.execute_reply":"2025-05-03T01:20:04.140654Z"}},"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-logloss:0.65531\n[1]\tvalidation_0-logloss:0.62717\n[2]\tvalidation_0-logloss:0.60348\n[3]\tvalidation_0-logloss:0.59248\n[4]\tvalidation_0-logloss:0.58331\n[5]\tvalidation_0-logloss:0.57435\n[6]\tvalidation_0-logloss:0.55352\n[7]\tvalidation_0-logloss:0.54721\n[8]\tvalidation_0-logloss:0.54119\n[9]\tvalidation_0-logloss:0.53407\n[10]\tvalidation_0-logloss:0.53047\n[11]\tvalidation_0-logloss:0.51731\n[12]\tvalidation_0-logloss:0.50465\n[13]\tvalidation_0-logloss:0.49573\n[14]\tvalidation_0-logloss:0.49364\n[15]\tvalidation_0-logloss:0.49288\n[16]\tvalidation_0-logloss:0.48742\n[17]\tvalidation_0-logloss:0.47982\n[18]\tvalidation_0-logloss:0.47809\n[19]\tvalidation_0-logloss:0.47575\n[20]\tvalidation_0-logloss:0.47125\n[21]\tvalidation_0-logloss:0.46834\n[22]\tvalidation_0-logloss:0.46570\n[23]\tvalidation_0-logloss:0.46409\n[24]\tvalidation_0-logloss:0.46226\n[25]\tvalidation_0-logloss:0.45853\n[26]\tvalidation_0-logloss:0.45479\n[27]\tvalidation_0-logloss:0.45238\n[28]\tvalidation_0-logloss:0.45122\n[29]\tvalidation_0-logloss:0.44893\n[30]\tvalidation_0-logloss:0.44864\n[31]\tvalidation_0-logloss:0.44701\n[32]\tvalidation_0-logloss:0.44565\n[33]\tvalidation_0-logloss:0.44546\n[34]\tvalidation_0-logloss:0.44507\n[35]\tvalidation_0-logloss:0.44312\n[36]\tvalidation_0-logloss:0.44257\n[37]\tvalidation_0-logloss:0.44089\n[38]\tvalidation_0-logloss:0.43837\n[39]\tvalidation_0-logloss:0.43731\n[40]\tvalidation_0-logloss:0.43657\n[41]\tvalidation_0-logloss:0.43655\n[42]\tvalidation_0-logloss:0.43570\n[43]\tvalidation_0-logloss:0.43721\n[44]\tvalidation_0-logloss:0.43739\n[45]\tvalidation_0-logloss:0.43735\n[46]\tvalidation_0-logloss:0.43702\n[47]\tvalidation_0-logloss:0.43681\n[48]\tvalidation_0-logloss:0.43733\n[49]\tvalidation_0-logloss:0.43747\n[50]\tvalidation_0-logloss:0.43738\n[51]\tvalidation_0-logloss:0.43686\n[52]\tvalidation_0-logloss:0.43755\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":183},{"cell_type":"markdown","source":"### Model training with grid search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'max_depth': [3, 4, 5],\n    'learning_rate': [0.01, 0.1, 0.2, 0.5],\n    'n_estimators': [50, 100, 200],\n    'subsample': [0.7, 0.8, 1.0],\n    'colsample_bytree': [0.7, 0.8, 1.0]\n}\n\ngrid_search = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    cv=5,\n    scoring='f1',\n    verbose=1,\n    n_jobs=-1\n)\n\ngrid_search.fit(X_train, y_train)\nbest_model = grid_search.best_estimator_\n\npreds = best_model.predict(ctest[features])\nctest[\"Survived\"] = preds\n\nctest[[\"PassengerId\", \"Survived\"]].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T01:14:58.982335Z","iopub.execute_input":"2025-05-03T01:14:58.982663Z","iopub.status.idle":"2025-05-03T01:15:34.059666Z","shell.execute_reply.started":"2025-05-03T01:14:58.982641Z","shell.execute_reply":"2025-05-03T01:15:34.058848Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n","output_type":"stream"}],"execution_count":179}]}